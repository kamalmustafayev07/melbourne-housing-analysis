{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a41aedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the path to the data directory\n",
    "data_dir = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Build the full path to the file\n",
    "file_path = os.path.join(data_dir, 'Melbourne.csv')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Replace all empty values with NaN\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Count how many duplicate rows exist\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Remove all duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Optional: reset the index after dropping duplicates\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3de5f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: ['Price', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude', 'Longtitude', 'Regionname', 'Propertycount']\n"
     ]
    }
   ],
   "source": [
    "# Function to check for missing values\n",
    "def check_missing_columns(df):\n",
    "    missing_cols = [col for col in df.columns if df[col].isnull().any()]\n",
    "    return missing_cols\n",
    "\n",
    "# Initial check for missing values\n",
    "cols_with_missing = check_missing_columns(df)\n",
    "print(\"Columns with missing values:\", cols_with_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "new_grouping_fill",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kamal Mustafayev\\AppData\\Local\\Temp\\ipykernel_5556\\82594779.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Suburb'].fillna(df['Suburb'].mode()[0], inplace=True)\n",
      "C:\\Users\\Kamal Mustafayev\\AppData\\Local\\Temp\\ipykernel_5556\\82594779.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Regionname'].fillna(df['Regionname'].mode()[0], inplace=True)\n",
      "C:\\Users\\Kamal Mustafayev\\AppData\\Local\\Temp\\ipykernel_5556\\82594779.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['CouncilArea'].fillna(df['CouncilArea'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fill grouping categorical columns first (Suburb, Regionname, CouncilArea)\n",
    "# Assume Suburb might have misses (even if not), fill with mode by Postcode (if available) or global mode\n",
    "df['Suburb'] = df['Suburb'].fillna(df.groupby('Postcode')['Suburb'].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan))\n",
    "df['Suburb'].fillna(df['Suburb'].mode()[0], inplace=True)\n",
    "\n",
    "# Fill Regionname with mode by Suburb, then global mode\n",
    "df['Regionname'] = df['Regionname'].fillna(df.groupby('Suburb')['Regionname'].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan))\n",
    "df['Regionname'].fillna(df['Regionname'].mode()[0], inplace=True)\n",
    "\n",
    "# Fill CouncilArea with mode by Suburb, then by Regionname\n",
    "df['CouncilArea'] = df['CouncilArea'].fillna(df.groupby('Suburb')['CouncilArea'].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan))\n",
    "df['CouncilArea'] = df['CouncilArea'].fillna(df.groupby('Regionname')['CouncilArea'].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan))\n",
    "df['CouncilArea'].fillna(df['CouncilArea'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fill_numerics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kamal Mustafayev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "C:\\Users\\Kamal Mustafayev\\AppData\\Local\\Temp\\ipykernel_5556\\3789620152.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Propertycount'].fillna(df['Propertycount'].median(), inplace=True)\n",
      "C:\\Users\\Kamal Mustafayev\\AppData\\Local\\Temp\\ipykernel_5556\\3789620152.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['YearBuilt'].fillna(df['YearBuilt'].median(), inplace=True)\n",
      "C:\\Users\\Kamal Mustafayev\\AppData\\Local\\Temp\\ipykernel_5556\\3789620152.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(round(df[column].mean(), 1), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Fill numerical columns based on groupings\n",
    "# Price: mean by Suburb, fallback to Regionname\n",
    "df['Price'] = df['Price'].fillna(df.groupby('Suburb')['Price'].transform(lambda x: round(x.mean(), 1)))\n",
    "df['Price'] = df['Price'].fillna(df.groupby('Regionname')['Price'].transform(lambda x: round(x.mean(), 1)))\n",
    "\n",
    "# 1️ Fill by Suburb (mode preferred, fallback to median)\n",
    "df['Propertycount'] = df.groupby('Suburb')['Propertycount'].transform(\n",
    "    lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else x.median())\n",
    ")\n",
    "# 2️ Fill remaining NaN by Regionname (mode preferred, fallback to median)\n",
    "df['Propertycount'] = df.groupby('Regionname')['Propertycount'].transform(\n",
    "    lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else x.median())\n",
    ")\n",
    "# 3️ Final fallback (in case there’s still something left)\n",
    "df['Propertycount'].fillna(df['Propertycount'].median(), inplace=True)\n",
    "\n",
    "# YearBuilt: median global (no strong grouping dependency)\n",
    "df['YearBuilt'].fillna(df['YearBuilt'].median(), inplace=True)\n",
    "\n",
    "# Bedroom2: mean global, or by Rooms if needed\n",
    "df['Bedroom2'] = df['Bedroom2'].fillna(df['Rooms'])\n",
    "\n",
    "# Other means: Bathroom, Car\n",
    "columns_to_replace_mean = ['Bathroom', 'Car']\n",
    "for column in columns_to_replace_mean:\n",
    "    df[column].fillna(round(df[column].mean(), 1), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "handle_zeros",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle zeros (replace invalid zeros with NaN and fill)\n",
    "zero_columns_to_replace = ['Distance', 'Landsize', 'BuildingArea', 'Postcode']\n",
    "for col in zero_columns_to_replace:\n",
    "    df[col] = df[col].replace(0, np.nan)\n",
    "    df[col] = df[col].fillna(df.groupby('Suburb')[col].transform('median'))\n",
    "    df[col] = df[col].fillna(df.groupby('Regionname')[col].transform('median'))\n",
    "\n",
    "# Bathroom zeros: median by Rooms\n",
    "df['Bathroom'] = df['Bathroom'].replace(0, np.nan)\n",
    "df['Bathroom'] = df['Bathroom'].fillna(df.groupby('Rooms')['Bathroom'].transform('median'))\n",
    "\n",
    "# Bedroom2 zeros: sync with Rooms\n",
    "df.loc[df['Bedroom2'] == 0, 'Bedroom2'] = df.loc[df['Bedroom2'] == 0, 'Rooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "drop_columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Drop unnecessary columns\n",
    "df.drop(columns=['Lattitude', 'Longtitude'], inplace=True)\n",
    "\n",
    "# Rename Rooms to Bedroom (after all Rooms-based fills)\n",
    "df = df.rename(columns={'Rooms': 'Bedroom'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fix_validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Fix invalid values\n",
    "# YearBuilt corrections\n",
    "replacements = {1196: 1996, 1800: 1900, 1830: 1930, 1850: 1950}\n",
    "df['YearBuilt'] = df['YearBuilt'].replace(replacements)\n",
    "mask = df['YearBuilt'] == 2106\n",
    "df.loc[mask, 'YearBuilt'] = df.loc[mask, 'Date'].str[-4:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "checks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All missing values gone? True\n",
      "Suburb short values: ['Kew']\n",
      "Address short values: []\n",
      "Type short values: ['h', 'u', 't']\n",
      "Method short values: ['SS', 'S', 'VB', 'SP', 'PI', 'SN', 'W', 'PN', 'SA']\n",
      "SellerG short values: ['Kay', 'Ray', 'RT', 'Jas', 'FN', 'Tim', 'HAR', 'RW', 'R&H', 'One', 'C21', 'GL', 'YPA', 'J', 'Del', 'ASL', 'Re', 'RE', 'Ham', 'Vic', 'Joe', 'Red', 'LJ', 'Win', 'New', 'MSM', 'S&L', 'Ken', 'JRW', 'Oak', 'Jim', 'Max', 'L', 'Ash', 'LLC', 'Ace', 'M.J', 'U', 'JY', 'Le', 'The', 'MJ', 'SN', 'P', 'PRD', 'T']\n",
      "Date short values: []\n",
      "CouncilArea short values: []\n",
      "Regionname short values: []\n",
      "Invalid dates: []\n",
      "Invalid YearBuilt: []\n",
      "Invalid Prices: []\n",
      "Invalid Postcodes: [3067. 3042. 3206. 3078. 3018. 3025. 3143. 3032. 3147. 3034. 3183. 3103.\n",
      " 3104. 3204. 3165. 3128. 3019. 3186. 3187. 3056. 3055. 3105. 3125. 3124.\n",
      " 3126. 3054. 3163. 3162. 3161. 3148. 3068. 3058. 3066. 3108. 3084. 3185.\n",
      " 3184. 3040. 3041. 3065. 3031. 3011. 3146. 3046. 3043. 3188. 3122. 3081.\n",
      " 3166. 3079. 3021. 3033. 3101. 3102. 3144. 3012. 3145. 3000. 3127. 3039.\n",
      " 3189. 3015. 3051. 3070. 3167. 3052. 3044. 3207. 3181. 3072. 3073. 3121.\n",
      " 3205. 3141. 3006. 3182. 3020. 3107. 3071. 3142. 3087. 3003. 3016. 3085.\n",
      " 3013. 3057. 3061. 3053. 3002. 3060. 3123. 3047. 3083. 3008. 3028. 3022.\n",
      " 3049. 3153. 3193. 3806. 3130. 3155. 3088. 3023. 3151. 3192. 3169. 3168.\n",
      " 3978. 3064. 3977. 3136. 3175. 3089. 3172. 3109. 3111. 3754. 3196. 3095.\n",
      " 3782. 3076. 3177. 3156. 3131. 3199. 3200. 3437. 3150. 3059. 3803. 3777.\n",
      " 3135. 3190. 3037. 3029. 3038. 3173. 3075. 3093. 3975. 3337. 3338. 3194.\n",
      " 3082. 3132. 3094. 3765. 3195. 3149. 3170. 3805. 3174. 3030. 3134. 3335.\n",
      " 3178. 3191. 3198. 3752. 3171. 3429. 3160. 3106. 3154. 3074. 3133. 3152.\n",
      " 3027. 3750. 3024. 3197. 3138. 3810. 3179. 3113. 3096. 3201. 3202. 3137.\n",
      " 3910. 3431. 3808. 3116. 3048. 3340. 3976. 3036. 3796. 3795. 3756. 3427.\n",
      " 3180. 3158. 3099. 3140. 3115. 3802. 3809. 3788. 3807. 3775. 3090. 3757.\n",
      " 3438. 3793.]\n",
      "Columns with zeros: ['Car']\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Final checks\n",
    "# Check for remaining missing values\n",
    "has_missing = df.isnull().values.any()\n",
    "print(\"All missing values gone?\", not has_missing)\n",
    "\n",
    "# Function to check string lengths\n",
    "def check_string_lengths(series, min_length=4):\n",
    "    return [val for val in series.unique() if isinstance(val, str) and len(val) < min_length]\n",
    "\n",
    "string_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "for col in string_cols:\n",
    "    print(f\"{col} short values: {check_string_lengths(df[col])}\")\n",
    "\n",
    "# Check dates\n",
    "def check_date_format(series, date_format=\"%d-%m-%Y\"):\n",
    "    invalid = []\n",
    "    for val in series:\n",
    "        try:\n",
    "            datetime.strptime(val, date_format)\n",
    "        except (ValueError, TypeError):\n",
    "            invalid.append(val)\n",
    "    return invalid\n",
    "\n",
    "print(\"Invalid dates:\", check_date_format(df['Date']))\n",
    "\n",
    "# Check invalid YearBuilt, Price, Postcode, etc.\n",
    "invalid_years = df[(df['YearBuilt'] <= 1850) | (df['YearBuilt'] > 2025)]['YearBuilt'].unique()\n",
    "print(\"Invalid YearBuilt:\", invalid_years)\n",
    "\n",
    "invalid_prices = df[df['Price'] <= 18000]['Price'].unique()\n",
    "print(\"Invalid Prices:\", invalid_prices)\n",
    "\n",
    "is_valid_postcode = (df['Postcode'].astype(str).str.len() == 4) & (df['Postcode'].astype(str).str.isdigit())\n",
    "invalid_postcodes = df[~is_valid_postcode]['Postcode'].unique()\n",
    "print(\"Invalid Postcodes:\", invalid_postcodes)\n",
    "\n",
    "# Check zeros in numerics\n",
    "def check_zero_columns(df):\n",
    "    zero_cols = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col]) and (df[col] == 0).any()]\n",
    "    return zero_cols\n",
    "\n",
    "print(\"Columns with zeros:\", check_zero_columns(df))\n",
    "\n",
    "# Replace all values in 'Bedroom2' that are 20 or 30 with 12\n",
    "df['Bedroom2'] = df['Bedroom2'].replace([20, 30], 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "type_conversions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Type conversions\n",
    "columns_to_int = ['YearBuilt', 'Postcode', 'Bedroom', 'Bedroom2', 'Car', 'Bathroom','Propertycount']\n",
    "for col in columns_to_int:\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset saved to: c:\\Users\\Kamal Mustafayev\\Desktop\\melbourne\\melbourne-housing-analysis\\data\\Melbourne_cleaned.csv\n",
      "       Suburb             Address  Bedroom Type      Price Method SellerG  \\\n",
      "0  Abbotsford       68 Studley St        2    h  1026500.0     SS  Jellis   \n",
      "1  Abbotsford        85 Turner St        2    h  1480000.0      S  Biggin   \n",
      "2  Abbotsford     25 Bloomburg St        2    h  1035000.0      S  Biggin   \n",
      "3  Abbotsford  18/659 Victoria St        3    u  1026500.0     VB  Rounds   \n",
      "4  Abbotsford        5 Charles St        3    h  1465000.0     SP  Biggin   \n",
      "\n",
      "         Date  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n",
      "0  03-09-2016       2.5      3067         2         1    1     126.0   \n",
      "1  03-12-2016       2.5      3067         2         1    1     202.0   \n",
      "2  04-02-2016       2.5      3067         2         1    0     156.0   \n",
      "3  04-02-2016       2.5      3067         3         2    1     181.5   \n",
      "4  04-03-2017       2.5      3067         3         2    0     134.0   \n",
      "\n",
      "   BuildingArea  YearBuilt CouncilArea             Regionname  Propertycount  \n",
      "0          98.0       1970       Yarra  Northern Metropolitan           4019  \n",
      "1          98.0       1970       Yarra  Northern Metropolitan           4019  \n",
      "2          79.0       1900       Yarra  Northern Metropolitan           4019  \n",
      "3          98.0       1970       Yarra  Northern Metropolitan           4019  \n",
      "4         150.0       1900       Yarra  Northern Metropolitan           4019  \n"
     ]
    }
   ],
   "source": [
    "# Build output file path\n",
    "output_path = os.path.join(data_dir, 'Melbourne_cleaned.csv')\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Cleaned dataset saved to: {output_path}\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
